# -*- coding: utf-8 -*-
"""CricketModel.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14jidO7yW-tRWYgvJlztcj1rRI0tfZrpR
"""

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Create project directory
!mkdir -p "/content/drive/MyDrive/IPL_Prediction_Model"

# Install required libraries
!pip install cricsheet pandas numpy matplotlib seaborn scikit-learn xgboost catboost

# Download data
!wget https://cricsheet.org/downloads/ipl.zip -P "/content/drive/MyDrive/IPL_Prediction_Model/data"
!unzip "/content/drive/MyDrive/IPL_Prediction_Model/data/ipl.zip" -d "/content/drive/MyDrive/IPL_Prediction_Model/data"

# Install required libraries
!pip install pandas numpy matplotlib seaborn scikit-learn xgboost catboost pyyaml beautifulsoup4 tqdm

!mkdir -p "/content/drive/MyDrive/IPL_Prediction_Model/data"
!mkdir -p "/content/drive/MyDrive/IPL_Prediction_Model/models"
!mkdir -p "/content/drive/MyDrive/IPL_Prediction_Model/results"

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import xgboost as xgb
from catboost import CatBoostClassifier
import warnings
warnings.filterwarnings('ignore')

# Fix the process_match_data function to handle seasons correctly
def process_match_data():
    """Process YAML match data files into a structured DataFrame"""
    import yaml
    import glob
    import os
    from tqdm.notebook import tqdm

    matches = []
    yaml_files = glob.glob("/content/drive/MyDrive/IPL_Prediction_Model/data/*.yaml")

    for file_path in tqdm(yaml_files, desc="Processing matches"):
        try:
            with open(file_path, 'r') as f:
                data = yaml.safe_load(f)

            # Skip matches without proper information
            if not data or 'info' not in data:
                continue

            # Extract basic match info
            match_info = {
                'match_id': os.path.basename(file_path).split('.')[0],
                'season': data['info'].get('season', 'Unknown'),  # Use int() if possible
                'date': data['info'].get('dates', ['Unknown'])[0],
                'venue': data['info'].get('venue', 'Unknown'),
                'city': data['info'].get('city', 'Unknown'),
                'team1': data['info']['teams'][0] if 'teams' in data['info'] and len(data['info']['teams']) > 0 else 'Unknown',
                'team2': data['info']['teams'][1] if 'teams' in data['info'] and len(data['info']['teams']) > 1 else 'Unknown',
            }

            # Add toss information if available
            if 'toss' in data['info']:
                match_info['toss_winner'] = data['info']['toss'].get('winner', 'Unknown')
                match_info['toss_decision'] = data['info']['toss'].get('decision', 'Unknown')
            else:
                match_info['toss_winner'] = 'Unknown'
                match_info['toss_decision'] = 'Unknown'

            # Add winner information if available
            if 'outcome' in data['info']:
                if 'winner' in data['info']['outcome']:
                    match_info['winner'] = data['info']['outcome']['winner']
                elif 'result' in data['info']['outcome']:
                    match_info['winner'] = 'no result'
                elif 'eliminator' in data['info']['outcome']:
                    match_info['winner'] = data['info']['outcome']['eliminator']
                else:
                    match_info['winner'] = 'Unknown'
            else:
                match_info['winner'] = 'Unknown'

            matches.append(match_info)
        except Exception as e:
            print(f"Error processing {file_path}: {e}")

    # Create DataFrame
    df = pd.DataFrame(matches)

    # Handle season data
    # If all seasons are unknown, create dummy seasons based on date
    if all(season == 'Unknown' for season in df['season']):
        print("All seasons unknown, creating seasons from dates")
        # Try to extract year from date
        df['season'] = df['date'].apply(lambda x: str(x).split('-')[0] if '-' in str(x) else 'Unknown')

    return df

def extract_team_stats(df):
    """Calculate team performance metrics per season"""
    # Create team stats DataFrame
    teams = pd.concat([df['team1'], df['team2']]).unique()
    seasons = df['season'].unique()

    team_stats = []

    for season in seasons:
        season_df = df[df['season'] == season]

        for team in teams:
            # Team matches in the season
            team_matches = season_df[(season_df['team1'] == team) | (season_df['team2'] == team)]

            if len(team_matches) == 0:
                continue

            # Team wins
            team_wins = len(season_df[season_df['winner'] == team])

            # Toss wins
            toss_wins = len(season_df[season_df['toss_winner'] == team])

            # Home matches
            home_matches = len(team_matches[team_matches['team1'] == team])

            # Away matches
            away_matches = len(team_matches[team_matches['team2'] == team])

            # Win rate
            win_rate = team_wins / len(team_matches) if len(team_matches) > 0 else 0

            # Toss win rate
            toss_win_rate = toss_wins / len(team_matches) if len(team_matches) > 0 else 0

            team_stats.append({
                'season': season,
                'team': team,
                'matches_played': len(team_matches),
                'wins': team_wins,
                'toss_wins': toss_wins,
                'home_matches': home_matches,
                'away_matches': away_matches,
                'win_rate': win_rate,
                'toss_win_rate': toss_win_rate
            })

    return pd.DataFrame(team_stats)

def calculate_head_to_head(df):
    """Calculate head-to-head statistics between teams"""
    teams = pd.concat([df['team1'], df['team2']]).unique()

    h2h_stats = []

    for team1 in teams:
        for team2 in teams:
            if team1 == team2:
                continue

            # Matches between the two teams
            matches = df[((df['team1'] == team1) & (df['team2'] == team2)) |
                         ((df['team1'] == team2) & (df['team2'] == team1))]

            if len(matches) == 0:
                continue

            # Team1 wins against team2
            team1_wins = len(matches[matches['winner'] == team1])

            # Team2 wins against team1
            team2_wins = len(matches[matches['winner'] == team2])

            # Win rate of team1 against team2
            team1_win_rate = team1_wins / len(matches) if len(matches) > 0 else 0

            h2h_stats.append({
                'team1': team1,
                'team2': team2,
                'matches_played': len(matches),
                'team1_wins': team1_wins,
                'team2_wins': team2_wins,
                'team1_win_rate': team1_win_rate
            })

    return pd.DataFrame(h2h_stats)

def process_player_data():
    """Process player statistics from HTML files"""
    from bs4 import BeautifulSoup

    # Process batting records
    try:
        with open("/content/drive/MyDrive/IPL_Prediction_Model/data/ipl_batting_records.html", 'r') as f:
            batting_html = f.read()

        batting_soup = BeautifulSoup(batting_html, 'html.parser')
        batting_table = batting_soup.find('table', class_='engineTable')

        batting_records = []

        if batting_table:
            rows = batting_table.find_all('tr')
            headers = [th.text.strip() for th in rows[0].find_all('th')]

            for row in rows[1:]:
                cols = row.find_all('td')
                if cols:
                    batting_records.append({
                        headers[i]: col.text.strip()
                        for i, col in enumerate(cols) if i < len(headers)
                    })
    except:
        batting_records = []

    # Process bowling records
    try:
        with open("/content/drive/MyDrive/IPL_Prediction_Model/data/ipl_bowling_records.html", 'r') as f:
            bowling_html = f.read()

        bowling_soup = BeautifulSoup(bowling_html, 'html.parser')
        bowling_table = bowling_soup.find('table', class_='engineTable')

        bowling_records = []

        if bowling_table:
            rows = bowling_table.find_all('tr')
            headers = [th.text.strip() for th in rows[0].find_all('th')]

            for row in rows[1:]:
                cols = row.find_all('td')
                if cols:
                    bowling_records.append({
                        headers[i]: col.text.strip()
                        for i, col in enumerate(cols) if i < len(headers)
                    })
    except:
        bowling_records = []

    return pd.DataFrame(batting_records), pd.DataFrame(bowling_records)

def create_model_features(matches_df, team_stats_df, h2h_df):
    """Create feature dataset for predictive modeling"""
    model_data = []

    for _, match in matches_df.iterrows():
        if match['winner'] in ['no result', 'tie', 'Unknown']:
            continue

        team1 = match['team1']
        team2 = match['team2']
        season = match['season']

        # Get team stats for the season
        team1_stats = team_stats_df[(team_stats_df['team'] == team1) &
                                    (team_stats_df['season'] == season)]
        team2_stats = team_stats_df[(team_stats_df['team'] == team2) &
                                    (team_stats_df['season'] == season)]

        # Skip if team stats are not available
        if len(team1_stats) == 0 or len(team2_stats) == 0:
            continue

        # Get head-to-head stats
        h2h_stats = h2h_df[(h2h_df['team1'] == team1) & (h2h_df['team2'] == team2)]

        if len(h2h_stats) == 0:
            h2h_stats = h2h_df[(h2h_df['team1'] == team2) & (h2h_df['team2'] == team1)]
            if len(h2h_stats) > 0:
                # Swap team1 and team2 stats
                h2h_stats = h2h_stats.rename(columns={
                    'team1_wins': 'team2_wins',
                    'team2_wins': 'team1_wins',
                    'team1_win_rate': 'team2_win_rate'
                })
                h2h_stats['team1_win_rate'] = 1 - h2h_stats['team2_win_rate']

        # Default h2h values if not available
        h2h_matches_played = h2h_stats['matches_played'].values[0] if len(h2h_stats) > 0 else 0
        h2h_team1_win_rate = h2h_stats['team1_win_rate'].values[0] if len(h2h_stats) > 0 else 0.5

        # Create feature record
        record = {
            'match_id': match['match_id'],
            'season': season,
            'team1': team1,
            'team2': team2,
            'venue': match['venue'],
            'city': match['city'],
            'toss_winner': match['toss_winner'],
            'toss_decision': match['toss_decision'],

            # Team 1 stats
            'team1_matches_played': team1_stats['matches_played'].values[0],
            'team1_wins': team1_stats['wins'].values[0],
            'team1_win_rate': team1_stats['win_rate'].values[0],
            'team1_toss_win_rate': team1_stats['toss_win_rate'].values[0],

            # Team 2 stats
            'team2_matches_played': team2_stats['matches_played'].values[0],
            'team2_wins': team2_stats['wins'].values[0],
            'team2_win_rate': team2_stats['win_rate'].values[0],
            'team2_toss_win_rate': team2_stats['toss_win_rate'].values[0],

            # Head-to-head stats
            'h2h_matches_played': h2h_matches_played,
            'h2h_team1_win_rate': h2h_team1_win_rate,

            # Is team1 toss winner?
            'is_team1_toss_winner': 1 if match['toss_winner'] == team1 else 0,

            # Target variable
            'team1_win': 1 if match['winner'] == team1 else 0
        }

        model_data.append(record)

    return pd.DataFrame(model_data)

# Process match data
matches_df = process_match_data()
print("Original matches_df seasons:", matches_df['season'].unique())

# Fix seasons if they're all Unknown
if all(season == 'Unknown' for season in matches_df['season']):
    print("All seasons unknown, creating seasons from dates")
    # Try to extract year from date
    matches_df['season'] = matches_df['date'].apply(lambda x: str(x).split('-')[0] if '-' in str(x) else 'Unknown')
    print("After fix - matches_df seasons:", matches_df['season'].unique())

matches_df.to_csv("/content/drive/MyDrive/IPL_Prediction_Model/data/matches.csv", index=False)

# Get team statistics
team_stats_df = extract_team_stats(matches_df)
team_stats_df.to_csv("/content/drive/MyDrive/IPL_Prediction_Model/data/team_stats.csv", index=False)

# Get head-to-head statistics
h2h_df = calculate_head_to_head(matches_df)
h2h_df.to_csv("/content/drive/MyDrive/IPL_Prediction_Model/data/head_to_head.csv", index=False)

# Process player data
batting_df, bowling_df = process_player_data()
batting_df.to_csv("/content/drive/MyDrive/IPL_Prediction_Model/data/batting_records.csv", index=False)
bowling_df.to_csv("/content/drive/MyDrive/IPL_Prediction_Model/data/bowling_records.csv", index=False)

# Create model features
model_df = create_model_features(matches_df, team_stats_df, h2h_df)

# Print some diagnostics
print("Season values:", model_df['season'].unique())
print("Total samples:", len(model_df))

# Convert season to numeric if needed
model_df['season'] = pd.to_numeric(model_df['season'], errors='coerce')
model_df = model_df.dropna(subset=['season'])

print("After conversion - Season values:", model_df['season'].unique())
print("After conversion - Total samples:", len(model_df))

model_df.to_csv("/content/drive/MyDrive/IPL_Prediction_Model/data/model_features.csv", index=False)

# Feature definition
features = [
    'team1_matches_played', 'team1_wins', 'team1_win_rate', 'team1_toss_win_rate',
    'team2_matches_played', 'team2_wins', 'team2_win_rate', 'team2_toss_win_rate',
    'h2h_matches_played', 'h2h_team1_win_rate', 'is_team1_toss_winner'
]

categorical_features = ['team1', 'team2', 'venue', 'city', 'toss_decision']

# Check if we have 2023 data
has_2023 = 2023 in model_df['season'].unique()
print(f"Has 2023 data: {has_2023}")

# Train-test split
if has_2023:
    # Use 2008-2022 for training, 2023 for testing
    train_data = model_df[model_df['season'] <= 2022]
    test_data = model_df[model_df['season'] == 2023]
else:
    # Use 80-20 split
    train_size = int(0.8 * len(model_df))
    train_data = model_df.iloc[:train_size]
    test_data = model_df.iloc[train_size:]

print(f"Training data size: {len(train_data)}")
print(f"Testing data size: {len(test_data)}")

X_train = train_data[features + categorical_features]
y_train = train_data['team1_win']

X_test = test_data[features + categorical_features]
y_test = test_data['team1_win']

# CHUNK 7
# Preprocessing pipeline
categorical_transformer = Pipeline(steps=[
    ('onehot', OneHotEncoder(handle_unknown='ignore'))
])

numerical_transformer = Pipeline(steps=[
    ('scaler', StandardScaler())
])

preprocessor = ColumnTransformer(
    transformers=[
        ('num', numerical_transformer, features),
        ('cat', categorical_transformer, categorical_features)
    ],
    remainder='drop'
)

# Define models
models = {
    'RandomForest': Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))
    ]),

    'XGBoost': Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('classifier', xgb.XGBClassifier(n_estimators=100, random_state=42))
    ]),

    'CatBoost': Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('classifier', CatBoostClassifier(iterations=100, random_state=42, verbose=0))
    ])
}

# Train models
for name, model in models.items():
    print(f"Training {name}...")
    model.fit(X_train, y_train)

    # Save model
    import joblib
    joblib.dump(model, f"/content/drive/MyDrive/IPL_Prediction_Model/models/{name}.pkl")

# Evaluate models
results = {}

for name, model in models.items():
    # Predictions on test set
    y_pred = model.predict(X_test)

    # Accuracy
    accuracy = accuracy_score(y_test, y_pred)

    # Classification report
    report = classification_report(y_test, y_pred, output_dict=True)

    # Confusion matrix
    cm = confusion_matrix(y_test, y_pred)

    results[name] = {
        'accuracy': accuracy,
        'report': report,
        'confusion_matrix': cm
    }

    print(f"{name} Accuracy: {accuracy:.4f}")
    print(f"{name} Classification Report:")
    print(classification_report(y_test, y_pred))

    # Plot confusion matrix
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=['Team 2 Win', 'Team 1 Win'],
                yticklabels=['Team 2 Win', 'Team 1 Win'])
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.title(f'Confusion Matrix - {name}')
    plt.savefig(f"/content/drive/MyDrive/IPL_Prediction_Model/results/{name}_confusion_matrix.png")
    plt.close()

# Find best model
best_model_name = max(results, key=lambda x: results[x]['accuracy'])
best_model = models[best_model_name]
best_accuracy = results[best_model_name]['accuracy']

print(f"Best Model: {best_model_name}")
print(f"Best Accuracy: {best_accuracy:.4f}")

# Hyperparameter Tuning for Best Model
if best_model_name == 'RandomForest':
    param_grid = {
        'classifier__n_estimators': [100, 200, 300],
        'classifier__max_depth': [None, 10, 20, 30],
        'classifier__min_samples_split': [2, 5, 10],
        'classifier__min_samples_leaf': [1, 2, 4]
    }
elif best_model_name == 'XGBoost':
    param_grid = {
        'classifier__n_estimators': [100, 200, 300],
        'classifier__learning_rate': [0.01, 0.1, 0.2],
        'classifier__max_depth': [3, 5, 7]
    }
else:  # CatBoost
    param_grid = {
        'classifier__iterations': [100, 200, 300],
        'classifier__learning_rate': [0.01, 0.1, 0.2],
        'classifier__depth': [4, 6, 8]
    }

# Grid search
grid_search = GridSearchCV(best_model, param_grid, cv=5, scoring='accuracy')
grid_search.fit(X_train, y_train)

print("Best Parameters:", grid_search.best_params_)
print("Best Cross-Validation Score:", grid_search.best_score_)

# Save tuned model
tuned_model = grid_search.best_estimator_
import joblib
joblib.dump(tuned_model, f"/content/drive/MyDrive/IPL_Prediction_Model/models/tuned_{best_model_name}.pkl")

# Evaluate tuned model
y_pred_tuned = tuned_model.predict(X_test)
tuned_accuracy = accuracy_score(y_test, y_pred_tuned)

print(f"Tuned {best_model_name} Accuracy: {tuned_accuracy:.4f}")
print(f"Tuned {best_model_name} Classification Report:")
print(classification_report(y_test, y_pred_tuned))

def prepare_ipl_2024_data():
    """Create a DataFrame for 2024 IPL matches"""
    # We should get the actual 2024 schedule and team info
    # For now, let's create a placeholder

    teams_2024 = [
        'Mumbai Indians',
        'Chennai Super Kings',
        'Royal Challengers Bangalore',
        'Kolkata Knight Riders',
        'Delhi Capitals',
        'Punjab Kings',
        'Rajasthan Royals',
        'Sunrisers Hyderabad',
        'Gujarat Titans',
        'Lucknow Super Giants'
    ]

    # Calculate team stats from 2023 season
    team_stats_2023 = team_stats_df[team_stats_df['season'] == 2023]

    # Create dummy schedule
    # In a real scenario, we would get the actual IPL 2024 schedule
    matches_2024 = []

    # Generate all possible team combinations
    import itertools
    team_combinations = list(itertools.combinations(teams_2024, 2))

    # Create matches (just an example, not the real schedule)
    for i, (team1, team2) in enumerate(team_combinations):
        matches_2024.append({
            'match_id': f'2024_{i+1}',
            'season': 2024,
            'team1': team1,
            'team2': team2,
            'venue': 'To be determined',
            'city': 'To be determined',
            'toss_winner': None,  # Will be known only before the match
            'toss_decision': None  # Will be known only before the match
        })

    # Create features for each match
    prediction_data = []

    for match in matches_2024:
        team1 = match['team1']
        team2 = match['team2']

        # Get team stats from 2023
        team1_stats = team_stats_2023[team_stats_2023['team'] == team1]
        team2_stats = team_stats_2023[team_stats_2023['team'] == team2]

        # Skip if team stats are not available
        if len(team1_stats) == 0 or len(team2_stats) == 0:
            continue

        # Get head-to-head stats
        h2h_stats = h2h_df[(h2h_df['team1'] == team1) & (h2h_df['team2'] == team2)]

        if len(h2h_stats) == 0:
            h2h_stats = h2h_df[(h2h_df['team1'] == team2) & (h2h_df['team2'] == team1)]
            if len(h2h_stats) > 0:
                # Swap team1 and team2 stats
                h2h_stats = h2h_stats.rename(columns={
                    'team1_wins': 'team2_wins',
                    'team2_wins': 'team1_wins',
                    'team1_win_rate': 'team2_win_rate'
                })
                h2h_stats['team1_win_rate'] = 1 - h2h_stats['team2_win_rate']

        # Default h2h values if not available
        h2h_matches_played = h2h_stats['matches_played'].values[0] if len(h2h_stats) > 0 else 0
        h2h_team1_win_rate = h2h_stats['team1_win_rate'].values[0] if len(h2h_stats) > 0 else 0.5

        # Create feature record
        # We'll create two versions - one for each toss outcome
        for toss_winner in [team1, team2]:
            for toss_decision in ['bat', 'field']:
                record = {
                    'match_id': match['match_id'],
                    'season': 2024,
                    'team1': team1,
                    'team2': team2,
                    'venue': match['venue'],
                    'city': match['city'],
                    'toss_winner': toss_winner,
                    'toss_decision': toss_decision,

                    # Team 1 stats
                    'team1_matches_played': team1_stats['matches_played'].values[0],
                    'team1_wins': team1_stats['wins'].values[0],
                    'team1_win_rate': team1_stats['win_rate'].values[0],
                    'team1_toss_win_rate': team1_stats['toss_win_rate'].values[0],

                    # Team 2 stats
                    'team2_matches_played': team2_stats['matches_played'].values[0],
                    'team2_wins': team2_stats['wins'].values[0],
                    'team2_win_rate': team2_stats['win_rate'].values[0],
                    'team2_toss_win_rate': team2_stats['toss_win_rate'].values[0],

                    # Head-to-head stats
                    'h2h_matches_played': h2h_matches_played,
                    'h2h_team1_win_rate': h2h_team1_win_rate,

                    # Is team1 toss winner?
                    'is_team1_toss_winner': 1 if toss_winner == team1 else 0,
                }

                prediction_data.append(record)

    return pd.DataFrame(prediction_data)

# Prepare 2024 prediction data
ipl_2024_data = prepare_ipl_2024_data()
ipl_2024_data.to_csv("/content/drive/MyDrive/IPL_Prediction_Model/data/ipl_2024_prediction_data.csv", index=False)

def predict_match(model, team1, team2, venue, city, toss_winner, toss_decision):
   """Predict the outcome of a match between team1 and team2"""
   # Get team stats from 2023 season
   team_stats_2023 = team_stats_df[team_stats_df['season'] == 2023]

   # Print available teams to debug
   print(f"Available teams in 2023: {team_stats_2023['team'].unique()}")

   team1_stats = team_stats_2023[team_stats_2023['team'] == team1]
   team2_stats = team_stats_2023[team_stats_2023['team'] == team2]

   # Check if team stats are available
   if len(team1_stats) == 0:
       print(f"No stats available for {team1}")
   if len(team2_stats) == 0:
       print(f"No stats available for {team2}")

   # Skip if team stats are not available
   if len(team1_stats) == 0 or len(team2_stats) == 0:
       # Use average stats instead
       avg_matches = team_stats_2023['matches_played'].mean()
       avg_wins = team_stats_2023['wins'].mean()
       avg_win_rate = team_stats_2023['win_rate'].mean()
       avg_toss_win_rate = team_stats_2023['toss_win_rate'].mean()

       if len(team1_stats) == 0:
           team1_stats = pd.DataFrame([{
               'team': team1,
               'matches_played': avg_matches,
               'wins': avg_wins,
               'win_rate': avg_win_rate,
               'toss_win_rate': avg_toss_win_rate
           }])

       if len(team2_stats) == 0:
           team2_stats = pd.DataFrame([{
               'team': team2,
               'matches_played': avg_matches,
               'wins': avg_wins,
               'win_rate': avg_win_rate,
               'toss_win_rate': avg_toss_win_rate
           }])

   # Get head-to-head stats
   h2h_stats = h2h_df[(h2h_df['team1'] == team1) & (h2h_df['team2'] == team2)]

   if len(h2h_stats) == 0:
       h2h_stats = h2h_df[(h2h_df['team1'] == team2) & (h2h_df['team2'] == team1)]
       if len(h2h_stats) > 0:
           # Swap team1 and team2 stats
           h2h_stats = h2h_stats.rename(columns={
               'team1_wins': 'team2_wins',
               'team2_wins': 'team1_wins',
               'team1_win_rate': 'team2_win_rate'
           })
           h2h_stats['team1_win_rate'] = 1 - h2h_stats['team2_win_rate']

   # Default h2h values if not available
   if len(h2h_stats) == 0:
       h2h_matches_played = 0
       h2h_team1_win_rate = 0.5  # Equal chance if no previous matches
   else:
       h2h_matches_played = h2h_stats['matches_played'].values[0]
       h2h_team1_win_rate = h2h_stats['team1_win_rate'].values[0]

   # Create feature record
   record = pd.DataFrame([{
       'team1': team1,
       'team2': team2,
       'venue': venue,
       'city': city,
       'toss_winner': toss_winner,
       'toss_decision': toss_decision,

       # Team 1 stats
       'team1_matches_played': team1_stats['matches_played'].values[0],
       'team1_wins': team1_stats['wins'].values[0],
       'team1_win_rate': team1_stats['win_rate'].values[0],
       'team1_toss_win_rate': team1_stats['toss_win_rate'].values[0],

       # Team 2 stats
       'team2_matches_played': team2_stats['matches_played'].values[0],
       'team2_wins': team2_stats['wins'].values[0],
       'team2_win_rate': team2_stats['win_rate'].values[0],
       'team2_toss_win_rate': team2_stats['toss_win_rate'].values[0],

       # Head-to-head stats
       'h2h_matches_played': h2h_matches_played,
       'h2h_team1_win_rate': h2h_team1_win_rate,

       # Is team1 toss winner?
       'is_team1_toss_winner': 1 if toss_winner == team1 else 0,
   }])

   # Make prediction
   try:
       prediction = model.predict(record)[0]
       proba = model.predict_proba(record)[0]

       if prediction == 1:
           return f"{team1} win with {proba[1]*100:.2f}% probability"
       else:
           return f"{team2} win with {proba[0]*100:.2f}% probability"
   except Exception as e:
       print(f"Error making prediction: {e}")
       return f"Unable to predict {team1} vs {team2} match"

# Example usage
print(predict_match(
   tuned_model,
   'Mumbai Indians',
   'Chennai Super Kings',
   'Wankhede Stadium',
   'Mumbai',
   'Mumbai Indians',
   'bat'
))

# After processing match data
matches_df = process_match_data()
print("Available seasons in matches_df:", matches_df['season'].unique())
print("Total matches:", len(matches_df))

# Check formatting of seasons (string vs int)
print("Season data type:", type(matches_df['season'].iloc[0]))

def extract_team_stats(df):
    """Calculate team performance metrics per season"""
    # Convert season to string for consistent comparison
    df = df.copy()
    df['season'] = df['season'].astype(str)

    # Continue with original function...

# Check if 2023 data exists
matches_2023 = matches_df[matches_df['season'] == '2023']
print("2023 matches found:", len(matches_2023))
print("2023 teams:", matches_2023['team1'].unique(), matches_2023['team2'].unique())

def extract_team_stats(df):
    """Calculate team performance metrics per season"""
    # Create team stats DataFrame
    teams = pd.concat([df['team1'], df['team2']]).unique()
    seasons = df['season'].unique()

    team_stats = []

    for season in seasons:
        season_df = df[df['season'] == season]

        for team in teams:
            # Team matches in the season
            team_matches = season_df[(season_df['team1'] == team) | (season_df['team2'] == team)]

            if len(team_matches) == 0:
                continue

            # Team wins
            team_wins = len(season_df[season_df['winner'] == team])

            # Toss wins
            toss_wins = len(season_df[season_df['toss_winner'] == team])

            # Home matches
            home_matches = len(team_matches[team_matches['team1'] == team])

            # Away matches
            away_matches = len(team_matches[team_matches['team2'] == team])

            # Win rate
            win_rate = team_wins / len(team_matches) if len(team_matches) > 0 else 0

            # Toss win rate
            toss_win_rate = toss_wins / len(team_matches) if len(team_matches) > 0 else 0

            team_stats.append({
                'season': season,
                'team': team,
                'matches_played': len(team_matches),
                'wins': team_wins,
                'toss_wins': toss_wins,
                'home_matches': home_matches,
                'away_matches': away_matches,
                'win_rate': win_rate,
                'toss_win_rate': toss_win_rate
            })

    return pd.DataFrame(team_stats)

# Run again
team_stats_df = extract_team_stats(matches_df)
print("Seasons in team_stats:", team_stats_df['season'].unique())
print("Teams in 2023:", team_stats_df[team_stats_df['season'] == '2023']['team'].unique())
print("Total team stats entries:", len(team_stats_df))

# Check if model_df exists
if 'model_df' in locals():
    print("Model features already created")
    print("Number of features:", len(model_df.columns))
    print("Number of samples:", len(model_df))
    print("Seasons available:", model_df['season'].unique())
else:
    print("Model features not created yet, running create_model_features...")
    model_df = create_model_features(matches_df, team_stats_df, h2h_df)
    model_df.to_csv("/content/drive/MyDrive/IPL_Prediction_Model/data/model_features.csv", index=False)
    print("Model features created with", len(model_df), "samples")

# Preprocessing pipeline
categorical_transformer = Pipeline(steps=[
    ('onehot', OneHotEncoder(handle_unknown='ignore'))
])

numerical_transformer = Pipeline(steps=[
    ('scaler', StandardScaler())
])

preprocessor = ColumnTransformer(
    transformers=[
        ('num', numerical_transformer, features),
        ('cat', categorical_transformer, categorical_features)
    ],
    remainder='drop'
)

# Define models
models = {
    'RandomForest': Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))
    ]),

    'XGBoost': Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('classifier', xgb.XGBClassifier(n_estimators=100, random_state=42))
    ]),

    'CatBoost': Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('classifier', CatBoostClassifier(iterations=100, random_state=42, verbose=0))
    ])
}

# Train models
for name, model in models.items():
    print(f"Training {name}...")
    model.fit(X_train, y_train)

    # Save model
    import joblib
    joblib.dump(model, f"/content/drive/MyDrive/IPL_Prediction_Model/models/{name}.pkl")

# Evaluate models
results = {}

for name, model in models.items():
    # Predictions on test set
    y_pred = model.predict(X_test)

    # Accuracy
    accuracy = accuracy_score(y_test, y_pred)

    # Classification report
    report = classification_report(y_test, y_pred, output_dict=True)

    # Confusion matrix
    cm = confusion_matrix(y_test, y_pred)

    results[name] = {
        'accuracy': accuracy,
        'report': report,
        'confusion_matrix': cm
    }

    print(f"{name} Accuracy: {accuracy:.4f}")
    print(f"{name} Classification Report:")
    print(classification_report(y_test, y_pred))

    # Plot confusion matrix
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=['Team 2 Win', 'Team 1 Win'],
                yticklabels=['Team 2 Win', 'Team 1 Win'])
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.title(f'Confusion Matrix - {name}')
    plt.savefig(f"/content/drive/MyDrive/IPL_Prediction_Model/results/{name}_confusion_matrix.png")
    plt.close()

# Find best model
best_model_name = max(results, key=lambda x: results[x]['accuracy'])
best_model = models[best_model_name]
best_accuracy = results[best_model_name]['accuracy']

print(f"Best Model: {best_model_name}")
print(f"Best Accuracy: {best_accuracy:.4f}")

# Hyperparameter Tuning for Best Model
if best_model_name == 'RandomForest':
    param_grid = {
        'classifier__n_estimators': [100, 200, 300],
        'classifier__max_depth': [None, 10, 20, 30],
        'classifier__min_samples_split': [2, 5, 10],
        'classifier__min_samples_leaf': [1, 2, 4]
    }
elif best_model_name == 'XGBoost':
    param_grid = {
        'classifier__n_estimators': [100, 200, 300],
        'classifier__learning_rate': [0.01, 0.1, 0.2],
        'classifier__max_depth': [3, 5, 7]
    }
else:  # CatBoost
    param_grid = {
        'classifier__iterations': [100, 200, 300],
        'classifier__learning_rate': [0.01, 0.1, 0.2],
        'classifier__depth': [4, 6, 8]
    }

# Grid search
grid_search = GridSearchCV(best_model, param_grid, cv=5, scoring='accuracy')
grid_search.fit(X_train, y_train)

print("Best Parameters:", grid_search.best_params_)
print("Best Cross-Validation Score:", grid_search.best_score_)

# Save tuned model
tuned_model = grid_search.best_estimator_
import joblib
joblib.dump(tuned_model, f"/content/drive/MyDrive/IPL_Prediction_Model/models/tuned_{best_model_name}.pkl")

# Evaluate tuned model
y_pred_tuned = tuned_model.predict(X_test)
tuned_accuracy = accuracy_score(y_test, y_pred_tuned)

print(f"Tuned {best_model_name} Accuracy: {tuned_accuracy:.4f}")
print(f"Tuned {best_model_name} Classification Report:")
print(classification_report(y_test, y_pred_tuned))

def prepare_ipl_2024_data():
    """Create a DataFrame for 2024 IPL matches"""
    # We should get the actual 2024 schedule and team info
    # For now, let's create a placeholder

    teams_2024 = [
        'Mumbai Indians',
        'Chennai Super Kings',
        'Royal Challengers Bangalore',
        'Kolkata Knight Riders',
        'Delhi Capitals',
        'Punjab Kings',
        'Rajasthan Royals',
        'Sunrisers Hyderabad',
        'Gujarat Titans',
        'Lucknow Super Giants'
    ]

    # Calculate team stats from 2023 season
    team_stats_2023 = team_stats_df[team_stats_df['season'] == 2023]

    # Create dummy schedule
    # In a real scenario, we would get the actual IPL 2024 schedule
    matches_2024 = []

    # Generate all possible team combinations
    import itertools
    team_combinations = list(itertools.combinations(teams_2024, 2))

    # Create matches (just an example, not the real schedule)
    for i, (team1, team2) in enumerate(team_combinations):
        matches_2024.append({
            'match_id': f'2024_{i+1}',
            'season': 2024,
            'team1': team1,
            'team2': team2,
            'venue': 'To be determined',
            'city': 'To be determined',
            'toss_winner': None,  # Will be known only before the match
            'toss_decision': None  # Will be known only before the match
        })

    # Create features for each match
    prediction_data = []

    for match in matches_2024:
        team1 = match['team1']
        team2 = match['team2']

        # Get team stats from 2023
        team1_stats = team_stats_2023[team_stats_2023['team'] == team1]
        team2_stats = team_stats_2023[team_stats_2023['team'] == team2]

        # Skip if team stats are not available
        if len(team1_stats) == 0 or len(team2_stats) == 0:
            continue

        # Get head-to-head stats
        h2h_stats = h2h_df[(h2h_df['team1'] == team1) & (h2h_df['team2'] == team2)]

        if len(h2h_stats) == 0:
            h2h_stats = h2h_df[(h2h_df['team1'] == team2) & (h2h_df['team2'] == team1)]
            if len(h2h_stats) > 0:
                # Swap team1 and team2 stats
                h2h_stats = h2h_stats.rename(columns={
                    'team1_wins': 'team2_wins',
                    'team2_wins': 'team1_wins',
                    'team1_win_rate': 'team2_win_rate'
                })
                h2h_stats['team1_win_rate'] = 1 - h2h_stats['team2_win_rate']

        # Default h2h values if not available
        h2h_matches_played = h2h_stats['matches_played'].values[0] if len(h2h_stats) > 0 else 0
        h2h_team1_win_rate = h2h_stats['team1_win_rate'].values[0] if len(h2h_stats) > 0 else 0.5

        # Create feature record
        # We'll create two versions - one for each toss outcome
        for toss_winner in [team1, team2]:
            for toss_decision in ['bat', 'field']:
                record = {
                    'match_id': match['match_id'],
                    'season': 2024,
                    'team1': team1,
                    'team2': team2,
                    'venue': match['venue'],
                    'city': match['city'],
                    'toss_winner': toss_winner,
                    'toss_decision': toss_decision,

                    # Team 1 stats
                    'team1_matches_played': team1_stats['matches_played'].values[0],
                    'team1_wins': team1_stats['wins'].values[0],
                    'team1_win_rate': team1_stats['win_rate'].values[0],
                    'team1_toss_win_rate': team1_stats['toss_win_rate'].values[0],

                    # Team 2 stats
                    'team2_matches_played': team2_stats['matches_played'].values[0],
                    'team2_wins': team2_stats['wins'].values[0],
                    'team2_win_rate': team2_stats['win_rate'].values[0],
                    'team2_toss_win_rate': team2_stats['toss_win_rate'].values[0],

                    # Head-to-head stats
                    'h2h_matches_played': h2h_matches_played,
                    'h2h_team1_win_rate': h2h_team1_win_rate,

                    # Is team1 toss winner?
                    'is_team1_toss_winner': 1 if toss_winner == team1 else 0,
                }

                prediction_data.append(record)

    return pd.DataFrame(prediction_data)

# Prepare 2024 prediction data
ipl_2024_data = prepare_ipl_2024_data()
ipl_2024_data.to_csv("/content/drive/MyDrive/IPL_Prediction_Model/data/ipl_2024_prediction_data.csv", index=False)

def predict_match(model, team1, team2, venue, city, toss_winner, toss_decision):
    """Predict the outcome of a match between team1 and team2"""
    # Debug prints
    print(f"Looking for stats for {team1} and {team2}")

    # Get team stats from 2023 season
    team_stats_2023 = team_stats_df[team_stats_df['season'] == '2023']  # Note: string comparison
    print(f"Found {len(team_stats_2023)} team entries for 2023")

    team1_stats = team_stats_2023[team_stats_2023['team'] == team1]
    team2_stats = team_stats_2023[team_stats_2023['team'] == team2]

    print(f"Stats for {team1}: {len(team1_stats)} entries")
    print(f"Stats for {team2}: {len(team2_stats)} entries")

    # Skip if team stats are not available
    if len(team1_stats) == 0 or len(team2_stats) == 0:
        # Use average stats instead
        avg_matches = team_stats_2023['matches_played'].mean()
        avg_wins = team_stats_2023['wins'].mean()
        avg_win_rate = team_stats_2023['win_rate'].mean()
        avg_toss_win_rate = team_stats_2023['toss_win_rate'].mean()

        if len(team1_stats) == 0:
            print(f"Using average stats for {team1}")
            team1_stats = pd.DataFrame([{
                'team': team1,
                'matches_played': avg_matches,
                'wins': avg_wins,
                'win_rate': avg_win_rate,
                'toss_win_rate': avg_toss_win_rate
            }])

        if len(team2_stats) == 0:
            print(f"Using average stats for {team2}")
            team2_stats = pd.DataFrame([{
                'team': team2,
                'matches_played': avg_matches,
                'wins': avg_wins,
                'win_rate': avg_win_rate,
                'toss_win_rate': avg_toss_win_rate
            }])

    # Get head-to-head stats
    h2h_stats = h2h_df[(h2h_df['team1'] == team1) & (h2h_df['team2'] == team2)]

    if len(h2h_stats) == 0:
        h2h_stats = h2h_df[(h2h_df['team1'] == team2) & (h2h_df['team2'] == team1)]
        if len(h2h_stats) > 0:
            # Swap team1 and team2 stats
            h2h_stats = h2h_stats.rename(columns={
                'team1_wins': 'team2_wins',
                'team2_wins': 'team1_wins',
                'team1_win_rate': 'team2_win_rate'
            })
            h2h_stats['team1_win_rate'] = 1 - h2h_stats['team2_win_rate']

    # Default h2h values if not available
    if len(h2h_stats) == 0:
        h2h_matches_played = 0
        h2h_team1_win_rate = 0.5  # Equal chance if no previous matches
    else:
        h2h_matches_played = h2h_stats['matches_played'].values[0]
        h2h_team1_win_rate = h2h_stats['team1_win_rate'].values[0]

    # Create feature record
    record = pd.DataFrame([{
        'team1': team1,
        'team2': team2,
        'venue': venue,
        'city': city,
        'toss_winner': toss_winner,
        'toss_decision': toss_decision,

        # Team 1 stats
        'team1_matches_played': team1_stats['matches_played'].values[0],
        'team1_wins': team1_stats['wins'].values[0],
        'team1_win_rate': team1_stats['win_rate'].values[0],
        'team1_toss_win_rate': team1_stats['toss_win_rate'].values[0],

        # Team 2 stats
        'team2_matches_played': team2_stats['matches_played'].values[0],
        'team2_wins': team2_stats['wins'].values[0],
        'team2_win_rate': team2_stats['win_rate'].values[0],
        'team2_toss_win_rate': team2_stats['toss_win_rate'].values[0],

        # Head-to-head stats
        'h2h_matches_played': h2h_matches_played,
        'h2h_team1_win_rate': h2h_team1_win_rate,

        # Is team1 toss winner?
        'is_team1_toss_winner': 1 if toss_winner == team1 else 0,
    }])

    # Make prediction
    try:
        prediction = model.predict(record)[0]
        proba = model.predict_proba(record)[0]

        if prediction == 1:
            return f"{team1} win with {proba[1]*100:.2f}% probability"
        else:
            return f"{team2} win with {proba[0]*100:.2f}% probability"
    except Exception as e:
        print(f"Error making prediction: {e}")
        return f"Unable to predict {team1} vs {team2} match"

# Example usage
print(predict_match(
    tuned_model,
    'Mumbai Indians',
    'Chennai Super Kings',
    'Wankhede Stadium',
    'Mumbai',
    'Mumbai Indians',
    'bat'
))

# --- 10. Testing on IPL 2024 ---
# When IPL 2024 schedule is available, we'll load it and make predictions
def load_ipl_2024_schedule():
    """Load the actual IPL 2024 schedule when available"""
    # In a real scenario, we would scrape or load the actual schedule
    # For now, we'll create a placeholder

    # Format: match_id, date, team1, team2, venue, city
    schedule = [
        # Sample matches - to be replaced with actual schedule
        ('2024_01', '2024-03-22', 'Chennai Super Kings', 'Royal Challengers Bangalore', 'M. A. Chidambaram Stadium', 'Chennai'),
        ('2024_02', '2024-03-23', 'Punjab Kings', 'Delhi Capitals', 'Punjab Cricket Association Stadium', 'Mohali'),
        ('2024_03', '2024-03-23', 'Kolkata Knight Riders', 'Sunrisers Hyderabad', 'Eden Gardens', 'Kolkata'),
        # Add more matches as per the actual schedule
    ]

    return pd.DataFrame(schedule, columns=['match_id', 'date', 'team1', 'team2', 'venue', 'city'])

# Function to make predictions for IPL 2024
def predict_ipl_2024(model):
    """Make predictions for IPL 2024 matches"""
    schedule = load_ipl_2024_schedule()
    predictions = []

    for _, match in schedule.iterrows():
        team1 = match['team1']
        team2 = match['team2']
        venue = match['venue']
        city = match['city']

        # We don't know toss results yet, so we'll predict both scenarios
        # Team 1 wins toss and bats
        pred1 = predict_match(model, team1, team2, venue, city, team1, 'bat')
        # Team 1 wins toss and fields
        pred2 = predict_match(model, team1, team2, venue, city, team1, 'field')
        # Team 2 wins toss and bats
        pred3 = predict_match(model, team1, team2, venue, city, team2, 'bat')
        # Team 2 wins toss and fields
        pred4 = predict_match(model, team1, team2, venue, city, team2, 'field')

        predictions.append({
            'match_id': match['match_id'],
            'date': match['date'],
            'team1': team1,
            'team2': team2,
            'venue': venue,
            'city': city,
            'team1_toss_bat': pred1,
            'team1_toss_field': pred2,
            'team2_toss_bat': pred3,
            'team2_toss_field': pred4
        })

    return pd.DataFrame(predictions)

# Make predictions
ipl_2024_predictions = predict_ipl_2024(tuned_model)
ipl_2024_predictions.to_csv("/content/drive/MyDrive/IPL_Prediction_Model/results/ipl_2024_predictions.csv", index=False)

# --- 12. Visualize Results ---
def visualize_model_performance():
    """Visualize model performance metrics"""
    # Accuracy comparison
    model_names = list(results.keys()) + ['Tuned ' + best_model_name]
    accuracies = [results[name]['accuracy'] for name in results.keys()] + [tuned_accuracy]

    plt.figure(figsize=(10, 6))
    bars = plt.bar(model_names, accuracies, color=['blue', 'green', 'orange', 'red'])
    plt.axhline(y=0.85, color='r', linestyle='--', label='Target (85%)')

    # Add accuracy values on top of bars
    for bar, acc in zip(bars, accuracies):
        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                f'{acc:.2%}', ha='center', fontweight='bold')

    plt.xlabel('Model')
    plt.ylabel('Accuracy')
    plt.title('Model Accuracy Comparison')
    plt.ylim(0, 1.0)
    plt.legend()
    plt.tight_layout()
    plt.savefig("/content/drive/MyDrive/IPL_Prediction_Model/results/model_accuracy_comparison.png")
    plt.close()

    # Feature importance (for the best model)
    if hasattr(tuned_model.named_steps['classifier'], 'feature_importances_'):
        # Get feature names after preprocessing
        preprocessor = tuned_model.named_steps['preprocessor']
        feature_names = (
            features +
            preprocessor.transformers_[1][1].named_steps['onehot'].get_feature_names_out(categorical_features).tolist()
        )

        # Get feature importances
        importances = tuned_model.named_steps['classifier'].feature_importances_

        # Plot top 15 features
        indices = np.argsort(importances)[-15:]
        plt.figure(figsize=(12, 8))
        plt.barh(range(len(indices)), importances[indices], align='center')
        plt.yticks(range(len(indices)), [feature_names[i] for i in indices])
        plt.xlabel('Feature Importance')
        plt.title(f'Top 15 Feature Importances - {best_model_name}')
        plt.tight_layout()
        plt.savefig("/content/drive/MyDrive/IPL_Prediction_Model/results/feature_importance.png")
        plt.close()

def create_dashboard():
    """Create an HTML dashboard for IPL predictions"""
    html_content = """
    <!DOCTYPE html>
    <html>
    <head>
        <title>IPL 2024 Match Predictions</title>
        <style>
            body {{
                font-family: Arial, sans-serif;
                margin: 0;
                padding: 20px;
                background-color: #f5f5f5;
            }}
            .container {{
                max-width: 1200px;
                margin: 0 auto;
                background-color: white;
                padding: 20px;
                border-radius: 10px;
                box-shadow: 0 0 10px rgba(0,0,0,0.1);
            }}
            h1, h2 {{
                color: #0078d7;
            }}
            table {{
                width: 100%;
                border-collapse: collapse;
                margin-top: 20px;
            }}
            th, td {{
                padding: 12px;
                text-align: left;
                border-bottom: 1px solid #ddd;
            }}
            th {{
                background-color: #0078d7;
                color: white;
            }}
            tr:hover {{
                background-color: #f1f1f1;
            }}
            .team-logo {{
                width: 30px;
                height: 30px;
                margin-right: 10px;
                vertical-align: middle;
            }}
            .prediction {{
                font-weight: bold;
                color: #0078d7;
            }}
            .model-info {{
                margin-top: 20px;
                padding: 15px;
                background-color: #f9f9f9;
                border-radius: 5px;
            }}
            .footer {{
                margin-top: 30px;
                text-align: center;
                color: #666;
            }}
        </style>
    </head>
    <body>
        <div class="container">
            <h1>IPL 2024 Match Predictions</h1>

            <div class="model-info">
                <h2>Model Information</h2>
                <p><strong>Best Model:</strong> {model_name}</p>
                <p><strong>Accuracy:</strong> {accuracy:.2%}</p>
                <p><strong>Target:</strong> 85% accuracy, predicting at least 65 out of 74 matches correctly</p>
            </div>

            <h2>Match Predictions</h2>
            <table>
                <tr>
                    <th>Date</th>
                    <th>Match</th>
                    <th>Venue</th>
                    <th>Prediction (After Toss)</th>
                </tr>
                {table_rows}
            </table>

            <div class="footer">
                <p> 2024 IPL Prediction Model - For educational purposes only</p>
            </div>
        </div>
    </body>
    </html>
    """

    # Get predictions
    predictions = pd.read_csv("/content/drive/MyDrive/IPL_Prediction_Model/results/ipl_2024_predictions.csv")

    # Generate table rows
    table_rows = ""
    for _, match in predictions.iterrows():
        table_rows += f"""
        <tr>
            <td>{match['date']}</td>
            <td>{match['team1']} vs {match['team2']}</td>
            <td>{match['venue']}, {match['city']}</td>
            <td>
                <p>If {match['team1']} wins toss & bats: <span class="prediction">{match['team1_toss_bat']}</span></p>
                <p>If {match['team1']} wins toss & fields: <span class="prediction">{match['team1_toss_field']}</span></p>
                <p>If {match['team2']} wins toss & bats: <span class="prediction">{match['team2_toss_bat']}</span></p>
                <p>If {match['team2']} wins toss & fields: <span class="prediction">{match['team2_toss_field']}</span></p>
            </td>
        </tr>
        """

    # Format HTML with model info
    html_content = html_content.format(
        model_name=f"Tuned {best_model_name}",
        accuracy=tuned_accuracy,
        table_rows=table_rows
    )

    # Save HTML file
    with open("/content/drive/MyDrive/IPL_Prediction_Model/results/ipl_2024_predictions_dashboard.html", "w") as f:
        f.write(html_content)

prediction = predict_match(
    tuned_model,
    'Kolkata Knight Riders',
    'Royal Challengers Bangalore',
    'Eden Gardens',
    'Kolkata',
    'Kolkata Knight Riders',  # Assuming KKR wins toss
    'bat'  # Assuming they choose to bat
)
print(prediction)

# Also try other toss scenarios
prediction2 = predict_match(
    tuned_model,
    'Kolkata Knight Riders',
    'Royal Challengers Bangalore',
    'Eden Gardens',
    'Kolkata',
    'Kolkata Knight Riders',
    'field'
)
print(prediction2)

prediction3 = predict_match(
    tuned_model,
    'Kolkata Knight Riders',
    'Royal Challengers Bangalore',
    'Eden Gardens',
    'Kolkata',
    'Royal Challengers Bangalore',
    'bat'
)
print(prediction3)

prediction4 = predict_match(
    tuned_model,
    'Kolkata Knight Riders',
    'Royal Challengers Bangalore',
    'Eden Gardens',
    'Kolkata',
    'Royal Challengers Bangalore',
    'field'
)
print(prediction4)

mi_csk = [
    predict_match(tuned_model, 'Mumbai Indians', 'Chennai Super Kings', 'Wankhede Stadium', 'Mumbai', 'Mumbai Indians', 'bat'),
    predict_match(tuned_model, 'Mumbai Indians', 'Chennai Super Kings', 'Wankhede Stadium', 'Mumbai', 'Mumbai Indians', 'field'),
    predict_match(tuned_model, 'Mumbai Indians', 'Chennai Super Kings', 'Wankhede Stadium', 'Mumbai', 'Chennai Super Kings', 'bat'),
    predict_match(tuned_model, 'Mumbai Indians', 'Chennai Super Kings', 'Wankhede Stadium', 'Mumbai', 'Chennai Super Kings', 'field')
]

for result in mi_csk:
    print(result)

gt_rr = [
    predict_match(tuned_model, 'Gujarat Titans', 'Rajasthan Royals', 'Narendra Modi Stadium', 'Ahmedabad', 'Gujarat Titans', 'bat'),
    predict_match(tuned_model, 'Gujarat Titans', 'Rajasthan Royals', 'Narendra Modi Stadium', 'Ahmedabad', 'Gujarat Titans', 'field'),
    predict_match(tuned_model, 'Gujarat Titans', 'Rajasthan Royals', 'Narendra Modi Stadium', 'Ahmedabad', 'Rajasthan Royals', 'bat'),
    predict_match(tuned_model, 'Gujarat Titans', 'Rajasthan Royals', 'Narendra Modi Stadium', 'Ahmedabad', 'Rajasthan Royals', 'field')
]

for result in gt_rr:
    print(result)

# List of upcoming matches
upcoming_matches = [
    ('Sunrisers Hyderabad', 'Rajasthan Royals', 'Rajiv Gandhi International Stadium', 'Hyderabad'),
    ('Chennai Super Kings', 'Mumbai Indians', 'M. A. Chidambaram Stadium', 'Chennai'),
    ('Delhi Capitals', 'Lucknow Super Giants', 'ACA-VDCA Cricket Stadium', 'Visakhapatnam'),
    ('Gujarat Titans', 'Punjab Kings', 'Narendra Modi Stadium', 'Ahmedabad'),
    ('Rajasthan Royals', 'Kolkata Knight Riders', 'Barsapara Cricket Stadium', 'Guwahati')
]

# Run predictions for each match
for team1, team2, venue, city in upcoming_matches:
    print(f"\n===== {team1} vs {team2} at {venue} =====")

    # Team 1 wins toss and bats
    pred1 = predict_match(tuned_model, team1, team2, venue, city, team1, 'bat')
    print(f"If {team1} wins toss & bats: {pred1}")

    # Team 1 wins toss and fields
    pred2 = predict_match(tuned_model, team1, team2, venue, city, team1, 'field')
    print(f"If {team1} wins toss & fields: {pred2}")

    # Team 2 wins toss and bats
    pred3 = predict_match(tuned_model, team1, team2, venue, city, team2, 'bat')
    print(f"If {team2} wins toss & bats: {pred3}")

    # Team 2 wins toss and fields
    pred4 = predict_match(tuned_model, team1, team2, venue, city, team2, 'field')
    print(f"If {team2} wins toss & fields: {pred4}")

